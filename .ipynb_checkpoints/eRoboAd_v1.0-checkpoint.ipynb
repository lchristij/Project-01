{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from MCForecastTools_fp import MCSimulation\n",
    "import numpy as np\n",
    "import datetime\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from datetime import date\n",
    "import logging\n",
    "import csv\n",
    "import json\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#\n",
    "import datetime as dt\n",
    "from MCForecastTools import MCSimulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpip_delta=datetime.timedelta(weeks=1)\n",
    "bpip_pair_delta=datetime.timedelta(weeks=4)\n",
    "bpip_delta10=datetime.timedelta(weeks=12)\n",
    "bpip_delta30=datetime.timedelta(weeks=205)\n",
    "\n",
    "# ISO 8601 week as number with Monday as the first day of the week then change date from string to int\n",
    "bpip_date = date.today()\n",
    "bpip_date_cast = bpip_date + bpip_delta10\n",
    "bpip_date_hist = bpip_date - bpip_delta30\n",
    "bpip_day_fdiff = (bpip_date_cast - bpip_date) / 7\n",
    "bpip_day_hdiff = (bpip_date - bpip_date_hist) / 7\n",
    "bpip_fdiff = bpip_day_fdiff.days\n",
    "bpip_hdiff = bpip_day_hdiff.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through url calendars for forcast data\n",
    "count=0\n",
    "df_ffxevents_list = []\n",
    "while(count < bpip_fdiff):\n",
    "    bpip_dfdelta=datetime.timedelta(weeks=count)\n",
    "    bpip_date_dfcast = bpip_date + bpip_dfdelta\n",
    "    print(f\"Forecast Date: {bpip_date_dfcast}\")\n",
    "    bpip_wk_dfcaststr = bpip_date_dfcast.strftime(\"%V\")\n",
    "    print(f\"Forecast Week String: {bpip_wk_dfcaststr}\")\n",
    "    bpip_yr_dfcaststr = bpip_date_dfcast.strftime(\"%Y\")\n",
    "    print(f\"Current Year String: {bpip_yr_dfcaststr}\")\n",
    "    bpip_yr_dfcastiso = bpip_date_dfcast.isocalendar()[0]\n",
    "    print(f\"Current Year: {bpip_yr_dfcastiso}\")\n",
    "    # get webpage and make the soup\n",
    "    babe_url = f\"https://www.babypips.com/economic-calendar?timezone=America%2FChicago&week={bpip_yr_dfcastiso}-W{bpip_wk_dfcaststr}\"\n",
    "    print(babe_url)\n",
    "    baseURL = requests.get(babe_url)\n",
    "    fxcal_soup = BeautifulSoup(baseURL.content, 'html.parser')\n",
    "\n",
    "    #Get all tag decendents \n",
    "    fxcal = fxcal_soup.find(class_=\"Table-module__table___2Nidf\")\n",
    "    fxcal_tbl_days = fxcal.find_all(class_=\"Section-module__container___2mwAW\")\n",
    "\n",
    "    #Loop through html classes and div tag elements\n",
    "    #df_ffxevents_list = []\n",
    "    for x in fxcal_tbl_days[0:]:\n",
    "        pd_news_day = [a.get_text() for a in x.select(\".Section-module__container___2mwAW .Table-module__name___1XC4z\")]\n",
    "        pd_month_day = [b.get_text() for b in x.select(\".Section-module__container___2mwAW .Table-module__month___2Efxb\") * len(pd_news_day)]\n",
    "        pd_date_day = [c.get_text() for c in x.select(\".Section-module__container___2mwAW .Table-module__dayNumber___1DiwN\") * len(pd_news_day)]\n",
    "        pd_wkday_day = [d.get_text() for d in x.select(\".Section-module__container___2mwAW .Table-module__weekday___1xUx_\") * len(pd_news_day)]\n",
    "        pd_time_day = [e.get_text() for e in x.select(\".Section-module__container___2mwAW .Table-module__time___iPjt3\")]\n",
    "        pd_curr_day = [f.get_text() for f in x.select(\".Section-module__container___2mwAW .Currency-module__code___1A32e\")]\n",
    "        pd_impact_day = [g.get_text() for g in x.select(\".Section-module__container___2mwAW .Impact-module__pill___2pcuA\")]\n",
    "        pd_forecast_day = [h.get_text() for h in x.select(\".Table-module__eventRow___2Z1BD .Table-module__forecast___3F_kh\")]\n",
    "        pd_previous_day = [i.get_text() for i in x.select(\".Table-module__eventRow___2Z1BD .Table-module__previous___1PJZ9\")]\n",
    "\n",
    "    #Build list elements into list of dataframes, concatenate dataframes and export to csv \n",
    "        df_ffxevents_day = pd.DataFrame.from_dict({\n",
    "        \"pd_year\": bpip_yr_dfcastiso,\n",
    "        \"pd_month\": pd_month_day,\n",
    "        \"pd_date\": pd_date_day,\n",
    "        \"pd_weekday\": pd_wkday_day,\n",
    "        \"pd_time\": pd_time_day,\n",
    "        \"pd_currency\": pd_curr_day,\n",
    "        \"pd_news\": pd_news_day,\n",
    "        \"pd_impact\": pd_impact_day,\n",
    "        \"pd_forecast\": pd_forecast_day,\n",
    "        \"pd_previous\": pd_previous_day})\n",
    "        df_ffxevents_list.append(df_ffxevents_day)\n",
    "    count = count + 1\n",
    "df_ffxevents_cat = pd.concat(df_ffxevents_list)\n",
    "df_ffxevents_cat.to_csv('fxevents_forecast.csv')\n",
    "count=0\n",
    "df_ffxevents_cat.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"fxevents_forecast.csv\")\n",
    "forecast_data = pd.read_csv(file_path)\n",
    "forecast_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data['Date'] = pd.to_datetime(forecast_data[['pd_month', 'pd_date', 'pd_year']].astype(str).agg('-'.join, axis=1))\n",
    "forecast_data.set_index(forecast_data['Date'], inplace=True)\n",
    "forecast_data = forecast_data.drop(columns=[\"pd_month\", \"pd_date\", \"pd_year\", \"pd_weekday\", \"Date\"])\n",
    "forecast_data = forecast_data.loc[:, ~forecast_data.columns.str.contains('^Unnamed')]\n",
    "forecast_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data = forecast_data[forecast_data['pd_currency'].isin(['USD', 'EUR', 'GBP', 'JPY'])]\n",
    "forecast_data = forecast_data[forecast_data['pd_impact'].isin(['high'])]\n",
    "forecast_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data[\"pd_forecast\"] = forecast_data[\"pd_forecast\"].fillna(0)\n",
    "forecast_data[\"pd_previous\"] = forecast_data[\"pd_previous\"].fillna(0)\n",
    "forecast_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data = forecast_data.rename(columns={\n",
    "    \"pd_time\": \"Time\",\n",
    "    \"pd_currency\": \"Currency\",\n",
    "    \"pd_news\": \"News\", \n",
    "    \"pd_impact\": \"Impact\",\n",
    "    \"pd_forecast\": \"Forecast\",\n",
    "    \"pd_previous\": \"Previous\"})\n",
    "forecast_data.to_csv(\"../Project-01/fxevents_forecast_GSd.csvfxevents_forecast_GSd.csv\")\n",
    "forecast_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast_path = Path(\"../fxevents_forecast_master.csv\")\n",
    "\n",
    "forecast_path = Path(\"../Project-01/fxevents_forecast_master.csv\")\n",
    "\n",
    "forecastmstr_data = pd.read_csv(forecast_path, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "forecastmstr_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastmstr_data[\"Previous\"] = forecastmstr_data[\"Previous\"].str.replace(\"*\", \"\").str.replace(\"%\", \"\").str.replace(\"k\", \"\").str.replace(\"B\", \"\").str.replace(\",\", \"\")\n",
    "forecastmstr_data[\"Forecast\"] = forecastmstr_data[\"Forecast\"].str.replace(\"*\", \"\").str.replace(\"%\", \"\").str.replace(\"k\", \"\").str.replace(\"B\", \"\").str.replace(\",\", \"\")    \n",
    "forecastmstr_data['Previous'] = forecastmstr_data['Previous'].astype('float')\n",
    "forecastmstr_data['Forecast'] = forecastmstr_data['Forecast'].astype('float')\n",
    "forecastmstr_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_menu():\n",
    "    print(\"[1] USD/JPY\")\n",
    "    print(\"[2] EUR/USD\")\n",
    "    print(\"[3] GBP/USD\")\n",
    "    print(\"[4] EXIT\")\n",
    "\n",
    "def get_pair_con(target_pair, base, quote):\n",
    "    print(f\"Retrieving 4-week forecast of high impact announcements for {target_pair}...\\n\")\n",
    "    # Get 4-week forecast for currency pair\n",
    "    bpip_pair_cast = bpip_date + bpip_pair_delta\n",
    "    forecastmstr_filter = forecastmstr_data.loc[bpip_date:bpip_pair_cast]\n",
    "    forecastmstr_filter_pair = forecastmstr_filter[forecastmstr_filter['Currency'].isin([base, quote])]\n",
    "    print(forecastmstr_filter_pair)\n",
    "    \n",
    "    # Get consensus for base currency - Positive Key\n",
    "    forecastmstr_filter_base = forecastmstr_filter[forecastmstr_filter['Currency'].isin([base])]\n",
    "    pos_base_filter = forecastmstr_filter_base.loc[forecastmstr_filter_base['Direction'] == 1]\n",
    "    base_pos_forcnt1 = sum(pos_base_filter.Forecast > pos_base_filter.Previous) #(default) sum of comparison to determining if news is positive for base currency\n",
    "    base_neg_forcnt1 = sum(pos_base_filter.Forecast < pos_base_filter.Previous) #sum of comparison to determining if news is negative for base currency\n",
    "    \n",
    "    # Get consensus for quoted currency - Positive Key\n",
    "    forecastmstr_filter_quote = forecastmstr_filter[forecastmstr_filter['Currency'].isin([quote])]\n",
    "    pos_quote_filter = forecastmstr_filter_quote.loc[forecastmstr_filter_quote['Direction'] == 1]\n",
    "    quote_pos_forcnt1 = sum(pos_quote_filter.Forecast > pos_quote_filter.Previous) #(default) sum of comparison to determining if news is positive for quote currency\n",
    "    quote_neg_forcnt1 = sum(pos_quote_filter.Forecast < pos_quote_filter.Previous) #sum of comparison to determining if news is negative for quote currency\n",
    "   \n",
    "    # -----------------------------------------------------------------------\n",
    "\n",
    "    # Get consensus for base currency - Negative Key\n",
    "    forecastmstr_filter_base = forecastmstr_filter[forecastmstr_filter['Currency'].isin([base])]\n",
    "    neg_base_filter = forecastmstr_filter_base.loc[forecastmstr_filter_base['Direction'] == -1]\n",
    "    base_pos_forcnt = sum(neg_base_filter.Forecast > neg_base_filter.Previous) #(default) sum of comparison to determining if news is positive for base currency\n",
    "    base_neg_forcnt = sum(neg_base_filter.Forecast < neg_base_filter.Previous) #sum of comparison to determining if news is negative for base currency\n",
    "    \n",
    "    # Get consensus for quoted currency - Negative Key\n",
    "    forecastmstr_filter_quote = forecastmstr_filter[forecastmstr_filter['Currency'].isin([quote])]\n",
    "    neg_quote_filter = forecastmstr_filter_quote.loc[forecastmstr_filter_quote['Direction'] == -1]\n",
    "    quote_pos_forcnt = sum(neg_quote_filter.Forecast > neg_quote_filter.Previous) #(default) sum of comparison to determining if news is positive for quote currency\n",
    "    quote_neg_forcnt = sum(neg_quote_filter.Forecast < neg_quote_filter.Previous) #sum of comparison to determining if news is negative for quote currency\n",
    "\n",
    "    #Total the number of positive vs. negative consensus for the base and quoted currency \n",
    "    tot_base_pos_sum = base_pos_forcnt1+base_pos_forcnt\n",
    "    tot_base_neg_sum = base_neg_forcnt1+base_neg_forcnt\n",
    "    tot_quote_pos_sum = quote_pos_forcnt1+quote_pos_forcnt\n",
    "    tot_quote_neg_sum = quote_neg_forcnt1+quote_neg_forcnt\n",
    "    \n",
    "    #Compare the number of positive vs. negative consensus for the base and quoted currency and give recommendation\n",
    "    if (tot_base_neg_sum > tot_base_pos_sum) and (tot_quote_pos_sum > tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall negative for the {base} and\"\n",
    "              f\" positive for the {quote} therefore the recommendation is to sell the {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum < tot_base_pos_sum) and (tot_quote_pos_sum < tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall positive for the {base} and negative for\"\n",
    "              f\" the {quote} therefore the recommendation is to buy {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum > tot_base_pos_sum) and (tot_quote_pos_sum < tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall neutral for the {base}/{quote}. Trade at\"\n",
    "              f\" your own discretion\")\n",
    "    elif (tot_base_neg_sum < tot_base_pos_sum) and (tot_quote_pos_sum > tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall neutral for the {base}/{quote}. Trade at\"\n",
    "              f\" your own discretion\")\n",
    "    elif (tot_base_neg_sum == tot_base_pos_sum) and (tot_quote_pos_sum < tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall positive for the {base} and negative for\"\n",
    "              f\" the {quote} therefore the recommendation is to buy {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum < tot_base_pos_sum) and (tot_quote_pos_sum == tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall positive for the {base} and negative for\"\n",
    "              f\" the {quote} therefore the recommendation is to buy {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum == tot_base_pos_sum) and (tot_quote_pos_sum > tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall negative for the {base} and positive for\"\n",
    "              f\" the {quote} therefore the recommendation is to sell the {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum > tot_base_pos_sum) and (tot_quote_pos_sum == tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall negative for the {base} and positive for\"\n",
    "              f\" the {quote} therefore the recommendation is to sell the {base}/{quote}\")\n",
    "    elif (tot_base_neg_sum == tot_base_pos_sum) and (tot_quote_pos_sum == tot_quote_neg_sum):\n",
    "        print(f\"The consensus for the next 4 weeks is overall neutral for the {base}/{quote}. Trade at\"\n",
    "              f\" your own discretion\")\n",
    "\n",
    "pair_menu()\n",
    "pair_option = int(input(\"Select the currency pair you wish to trade: \"))\n",
    "\n",
    "while pair_option != 4:\n",
    "    if pair_option == 1:\n",
    "        #get USDJPY news events & provide recommendation\n",
    "        get_pair_con('USD/JPY', 'USD', 'JPY')\n",
    "    elif pair_option == 2:\n",
    "        #get EURUSD news events & provide recommendation\n",
    "        get_pair_con('EUR/USD', 'EUR', 'USD')\n",
    "    elif pair_option == 3:\n",
    "        #get GBPUSD news events & provide recommendation\n",
    "        get_pair_con('GBP/USD', 'GBP', 'USD')\n",
    "    else:\n",
    "        print(f\"Invalid selection. please choose a valid option \")\n",
    "\n",
    "    print()\n",
    "    pair_menu()\n",
    "    pair_option = int(input(\"Select the currency pair you wish to trade: \"))\n",
    "\n",
    "print(f\"Thanks for using the FOREX Robo Advisor. Happy Trading!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin monte carlo simulation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_key = os.getenv(\"RAPIDAPI_KEY\")\n",
    "print(len(ra_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://alpha-vantage.p.rapidapi.com/query\"\n",
    "\n",
    "eur_querystring = {\"from_symbol\":\"EUR\",\"function\":\"FX_DAILY\",\"to_symbol\":\"USD\",\"outputsize\":\"full\",\"datatype\":\"csv\"}\n",
    "jpy_querystring = {\"from_symbol\":\"USD\",\"function\":\"FX_DAILY\",\"to_symbol\":\"JPY\",\"outputsize\":\"full\",\"datatype\":\"csv\"}\n",
    "gbp_querystring = {\"from_symbol\":\"GBP\",\"function\":\"FX_DAILY\",\"to_symbol\":\"USD\",\"outputsize\":\"full\",\"datatype\":\"csv\"}\n",
    "headers = {\n",
    "    'x-rapidapi-key': ra_key,\n",
    "    'x-rapidapi-host': \"alpha-vantage.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "eur_response = requests.request(\"GET\", url, headers=headers, params=eur_querystring)\n",
    "jpy_response = requests.request(\"GET\", url, headers=headers, params=jpy_querystring)\n",
    "gbp_response = requests.request(\"GET\", url, headers=headers, params=gbp_querystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('euro')\n",
    "print(eur_response.text)\n",
    "print('yen')\n",
    "print(jpy_response.text)\n",
    "print('pound')\n",
    "print(gbp_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_data = eur_response.text\n",
    "eur_df = pd.DataFrame([x.split(',') for x in eur_data.splitlines()])\n",
    "eur_df.columns = eur_df.iloc[0]\n",
    "eur_df = eur_df[1:]\n",
    "eur_df.columns = ['datetime', 'open', 'high', 'low', 'close']\n",
    "\n",
    "jpy_data = jpy_response.text\n",
    "jpy_df = pd.DataFrame([x.split(',') for x in jpy_data.splitlines()])\n",
    "jpy_df.columns = jpy_df.iloc[0]\n",
    "jpy_df = jpy_df[1:]\n",
    "jpy_df.columns = ['datetime', 'open', 'high', 'low', 'close']\n",
    "\n",
    "gbp_data = gbp_response.text\n",
    "gbp_df = pd.DataFrame([x.split(',') for x in gbp_data.splitlines()])\n",
    "gbp_df.columns = gbp_df.iloc[0]\n",
    "gbp_df = gbp_df[1:]\n",
    "gbp_df.columns = ['datetime', 'open', 'high', 'low', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'eur':eur_df, 'jpy':jpy_df, 'gbp':gbp_df}\n",
    "\n",
    "curr_fx=pd.concat(d.values(),axis=1, keys=d.keys())\n",
    "curr_fx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fx['eur','open'] = curr_fx['eur','open'].astype(float)\n",
    "curr_fx['eur','high'] = curr_fx['eur','high'].astype(float)\n",
    "curr_fx['eur','low'] = curr_fx['eur','low'].astype(float)\n",
    "curr_fx['eur','close'] = curr_fx['eur','close'].astype(float)\n",
    "\n",
    "\n",
    "curr_fx['jpy','open'] = curr_fx['jpy','open'].astype(float)\n",
    "curr_fx['jpy','high'] = curr_fx['jpy','high'].astype(float)\n",
    "curr_fx['jpy','low'] = curr_fx['jpy','low'].astype(float)\n",
    "curr_fx['jpy','close'] = curr_fx['jpy','close'].astype(float)\n",
    "\n",
    "curr_fx['gbp','open'] = curr_fx['gbp','open'].astype(float)\n",
    "curr_fx['gbp','high'] = curr_fx['gbp','high'].astype(float)\n",
    "curr_fx['gbp','low'] = curr_fx['gbp','low'].astype(float)\n",
    "curr_fx['gbp','close'] = curr_fx['gbp','close'].astype(float)\n",
    "\n",
    "curr_fx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_fx.xs('close',level=1,axis=1).pct_change()\n",
    "\n",
    "MC_even_dist = MCSimulation(\n",
    "    portfolio_data = curr_fx,\n",
    "    weights = [.33,.33,.33],\n",
    "    num_simulation = 1000,\n",
    "    num_trading_days = 40*31\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_even_dist.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_even_dist.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot = MC_even_dist.plot_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plot = MC_even_dist.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_tbl = MC_even_dist.summarize_cumulative_return()\n",
    "\n",
    "# Print summary statistics\n",
    "print(even_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lower and upper `95%` confidence intervals to calculate the range of the possible outcomes of our $10,000 investments\n",
    "even_tbl_ci_lower = round(even_tbl[8]*10000,2)\n",
    "even_tbl_ci_upper = round(even_tbl[9]*10000,2)\n",
    "\n",
    "# Print results\n",
    "print(f\"There is a 95% chance that an initial investment of $10,000 in the portfolio\"\n",
    "      f\" over the next 5 years will end within in the range of\"\n",
    "      f\" ${even_tbl_ci_lower} and ${even_tbl_ci_upper}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_fx2=pd.concat([eur_df, jpy_df, gbp_df], axis=1, sort=False)\n",
    "curr_fx2.columns = ['datetime', 'eur_open', 'eur_high', 'eur_low', 'eur_close', 'jpy_date', 'jpy_open', 'jpy_high', 'jpy_low', 'jpy_close', 'gbp_date', 'gbp_open', 'gbp_high', 'gbp_low', 'gbp_close']\n",
    "curr_fx2 = curr_fx2.drop(columns=['jpy_date', 'gbp_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fx2['datetime'] = pd.to_datetime(curr_fx2['datetime'])\n",
    "curr_fx2.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fx2['eur_open'] = curr_fx2['eur_open'].astype(float)\n",
    "curr_fx2['eur_high'] = curr_fx2['eur_high'].astype(float)\n",
    "curr_fx2['eur_low'] = curr_fx2['eur_low'].astype(float)\n",
    "curr_fx2['eur_close'] = curr_fx2['eur_close'].astype(float)\n",
    "curr_fx2['jpy_open'] = curr_fx2['jpy_open'].astype(float)\n",
    "curr_fx2['jpy_high'] = curr_fx2['jpy_high'].astype(float)\n",
    "curr_fx2['jpy_low'] = curr_fx2['jpy_low'].astype(float)\n",
    "curr_fx2['jpy_close'] = curr_fx2['jpy_close'].astype(float)\n",
    "curr_fx2['gbp_open'] = curr_fx2['gbp_open'].astype(float)\n",
    "curr_fx2['gbp_high'] = curr_fx2['gbp_high'].astype(float)\n",
    "curr_fx2['gbp_low'] = curr_fx2['gbp_low'].astype(float)\n",
    "curr_fx2['gbp_close'] = curr_fx2['gbp_close'].astype(float)\n",
    "curr_fx2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_fx2.hvplot(x='datetime', y=['eur_close',],width=800, height=600, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_fx2.hvplot(x='datetime', y=['jpy_close',],width=800, height=600, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_fx2.hvplot(x='datetime', y=['gbp_close'],width=800, height=600, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pn.widgets.Select(name='currency', options=['eur_open',\n",
    "                                                'eur_high',\n",
    "                                                'eur_low',\n",
    "                                                'eur_close',\n",
    "                                                'jpy_open',\n",
    "                                                'jpy_high',\n",
    "                                                'jpy_low',\n",
    "                                                'jpy_close',\n",
    "                                                'gbp_open',\n",
    "                                                'gbp_high',\n",
    "                                                'gbp_low',\n",
    "                                                'gbp_close'])\n",
    "\n",
    "plot1 = curr_fx2.hvplot(y=y, width=600, height=400, grid=True)\n",
    "plot2 = MC_even_dist.plot_simulation()\n",
    "\n",
    "pn.Column(plot1, y)\n",
    "#line_plot = MC_even_dist.plot_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
